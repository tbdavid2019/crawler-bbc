
# Web Scraper

This Python script is a versatile and customizable web scraper designed for extracting articles or specific content from websites. It includes robust logging and handles potential issues such as rate-limiting and incomplete data gracefully.

## Features

- **Custom Logging**: Logs scraping progress and issues to both the console and a log file (`scraper.log`).
- **HTML Parsing**: Utilizes `BeautifulSoup` for efficient HTML parsing and content extraction.
- **Throttling**: Implements random delays between requests to reduce the risk of getting blocked.
- **Error Handling**: Handles common issues such as HTTP errors, timeouts, and short/incomplete content gracefully.
- **Configurable Selectors**: Easily customize the link and content selectors for different websites.

## Requirements

To run the script, ensure you have the following Python packages installed:

- `requests`
- `beautifulsoup4`

Install them using pip:

```bash
pip install requests beautifulsoup4
```

How to Use

1.	Modify Scraping Configuration
Update the following parameters in the script based on your target website:
	â€¢	base_url: The root URL of the website to scrape.
	â€¢	link_selector: CSS selector for identifying links to the articles.
	â€¢	content_selector: CSS selector for extracting the desired content.

2.	Run the Script
Execute the script in your Python environment:
```
python scraper.py
```

3.	View Results
	â€¢	The scraped data will be saved in a text file (e.g., BBC_file.txt).
	â€¢	Logs of the scraping process will be stored in scraper.log.


---
Example Configuration

The script includes a pre-configured example for scraping articles from BBC News:
	â€¢	Base URL: https://www.bbc.com
	â€¢	Link Selector: a[href^='/news/articles/']
	â€¢	Content Selector: p
	â€¢	Output File: BBC_file.txt

Logging

The script outputs logs to both the console and a file (scraper.log):
	â€¢	Console: Ensures logs are visible in interactive environments like Google Colab.
	â€¢	Log File: Contains detailed information for debugging and reference.

Notes

â€¢	Ensure you comply with the terms of service of the websites you scrape.
â€¢	Use this script responsibly and avoid overloading servers.


License

This project is licensed under the MIT License. Feel free to modify and use it as needed.

---
ç¶²é çˆ¬èŸ²å·¥å…·

æ­¤ Python è…³æœ¬æ˜¯ä¸€å€‹å¤šåŠŸèƒ½ä¸”å¯è‡ªå®šç¾©çš„ç¶²é çˆ¬èŸ²ï¼Œå°ˆç‚ºå¾ç¶²ç«™ä¸­æå–æ–‡ç« æˆ–ç‰¹å®šå…§å®¹è€Œè¨­è¨ˆã€‚å®ƒåŒ…æ‹¬ç©©å¥çš„æ—¥èªŒè¨˜éŒ„åŠŸèƒ½ï¼Œä¸¦èƒ½æœ‰æ•ˆè™•ç†é€Ÿç‡é™åˆ¶å’Œè³‡æ–™ä¸å®Œæ•´ç­‰æ½›åœ¨å•é¡Œã€‚

åŠŸèƒ½ç‰¹é»

â€¢	è‡ªå®šç¾©æ—¥èªŒï¼šå°‡çˆ¬å–é€²åº¦å’Œå•é¡Œè¨˜éŒ„åˆ°æ§åˆ¶å°èˆ‡æ—¥èªŒæ–‡ä»¶ï¼ˆscraper.logï¼‰ã€‚
â€¢	HTML è§£æï¼šä½¿ç”¨ BeautifulSoup é€²è¡Œé«˜æ•ˆçš„ HTML è§£æå’Œå…§å®¹æå–ã€‚
â€¢	è«‹æ±‚ç¯€æµï¼šåœ¨è«‹æ±‚é–“éš¨æ©Ÿå»¶é²ï¼Œé™ä½è¢«å°é–çš„é¢¨éšªã€‚
â€¢	éŒ¯èª¤è™•ç†ï¼šå¦¥å–„è™•ç† HTTP éŒ¯èª¤ã€è¶…æ™‚åŠéçŸ­/ä¸å®Œæ•´çš„å…§å®¹ã€‚
â€¢	å¯é…ç½®é¸æ“‡å™¨ï¼šè¼•é¬†è‡ªå®šç¾©ä¸åŒç¶²ç«™çš„é€£çµèˆ‡å…§å®¹é¸æ“‡å™¨ã€‚



ç’°å¢ƒéœ€æ±‚

åŸ·è¡Œæ­¤è…³æœ¬éœ€è¦å®‰è£ä»¥ä¸‹ Python å¥—ä»¶ï¼š
	â€¢	requests
	â€¢	beautifulsoup4

ä½¿ç”¨ pip å®‰è£ï¼š

pip install requests beautifulsoup4

ä½¿ç”¨æ–¹æ³•

1.	ä¿®æ”¹çˆ¬å–é…ç½®
æ ¹æ“šç›®æ¨™ç¶²ç«™æ›´æ–°è…³æœ¬ä¸­çš„ä»¥ä¸‹åƒæ•¸ï¼š
	â€¢	base_urlï¼šè¦çˆ¬å–çš„ç¶²ç«™æ ¹ç¶²å€ã€‚
	â€¢	link_selectorï¼šç”¨æ–¼è­˜åˆ¥æ–‡ç« é€£çµçš„ CSS é¸æ“‡å™¨ã€‚
	â€¢	content_selectorï¼šç”¨æ–¼æå–å…§å®¹çš„ CSS é¸æ“‡å™¨ã€‚

2.	åŸ·è¡Œè…³æœ¬
åœ¨ Python ç’°å¢ƒä¸­åŸ·è¡Œè…³æœ¬ï¼š
```
python scraper.py
```

3.	æŸ¥çœ‹çµæœ
	â€¢	çˆ¬å–çš„è³‡æ–™å°‡å„²å­˜åœ¨æ–‡æœ¬æ–‡ä»¶ä¸­ï¼ˆä¾‹å¦‚ï¼šBBC_file.txtï¼‰ã€‚
	â€¢	çˆ¬å–éç¨‹çš„æ—¥èªŒè¨˜éŒ„åœ¨ scraper.log æ–‡ä»¶ä¸­ã€‚


ç¤ºä¾‹é…ç½®

è…³æœ¬ä¸­åŒ…å«é è¨­é…ç½®ï¼Œç”¨æ–¼å¾ BBC News çˆ¬å–æ–‡ç« ï¼š
	â€¢	æ ¹ç¶²å€ï¼šhttps://www.bbc.com
	â€¢	é€£çµé¸æ“‡å™¨ï¼ša[href^='/news/articles/']
	â€¢	å…§å®¹é¸æ“‡å™¨ï¼šp
	â€¢	è¼¸å‡ºæ–‡ä»¶ï¼šBBC_file.txt

æ—¥èªŒè¨˜éŒ„

è…³æœ¬å°‡æ—¥èªŒè¼¸å‡ºè‡³æ§åˆ¶å°èˆ‡æ–‡ä»¶ï¼ˆscraper.logï¼‰ï¼š
	â€¢	æ§åˆ¶å°ï¼šç¢ºä¿åœ¨äº’å‹•ç’°å¢ƒï¼ˆå¦‚ Google Colabï¼‰ä¸­å¯è¦‹æ—¥èªŒã€‚
	â€¢	æ—¥èªŒæ–‡ä»¶ï¼šè©³ç´°è¨˜éŒ„èª¿è©¦èˆ‡åƒè€ƒè³‡è¨Šã€‚

æ³¨æ„äº‹é …
â€¢	è«‹ç¢ºä¿éµå®ˆç›®æ¨™ç¶²ç«™çš„æœå‹™æ¢æ¬¾ã€‚
â€¢	è² è²¬ä»»åœ°ä½¿ç”¨æ­¤è…³æœ¬ï¼Œé¿å…éåº¦è«‹æ±‚ä¼ºæœå™¨ã€‚


æˆæ¬Š

æ­¤é …ç›®åŸºæ–¼ MIT æˆæ¬Šã€‚æ‚¨å¯è‡ªç”±ä¿®æ”¹ä¸¦ä½¿ç”¨æ­¤è…³æœ¬ã€‚

Happy scraping! ğŸ•¸ï¸ çˆ¬å–æ„‰å¿«ï¼

